---
title: "Effect size benchmark"
header-includes: \usepackage{amsmath}
output:
  html_document:
    toc: yes
    toc_depth: '2'
    df_print: paged
  pdf_document:
    toc: yes
    toc_depth: 2
    number_sections: yes
    keep_tex: no
---

# Introduction

Our aim is to provide the empirical effect size benchmark using publication-bias adjusted meta-analytic mean effects. This is meaningful, although people would argue that the interpretation of effect size is dependent on the research question at hand.

The existing effect size benchmark has four issues:

(1) Cohen's benchmark is basically based on his intuition and not evidence-based;

(2) Some researchers provide empirical benchmarks, but they do not account for publication bias;

(3) The simple use of absolute value of the effect size overlooks the  distributional properties (e.g., shape and skewness);

(4) When users interpret the magnitude of effect size, they ignore the sampling variance around the estimation.

# Packages

```{r package, warning=FALSE, echo=TRUE}
set.seed(2024)
suppressPackageStartupMessages({
  library(dplyr)
  library(readr)
  library(tidyr) 
  library(here)
  library(ggplot2)
  library(ggpubr)
  library(metafor)
  library(metaSEM)
  library(TOSTER)
  library(cowplot)
  library(raincloudplots)
  library(patchwork)
  library(RoBMA)}
  )
```

# Function

Function calculating mean and variance based on folded distribution

```{r fun}
## folded mean
folded_es <-function(mean, variance){   
  mu <- mean
  sigma <- sqrt(variance)
  fold_mu <- sigma*sqrt(2/pi)*exp((-mu^2)/(2*sigma^2)) + mu*(1 - 2*pnorm(-mu/sigma))
  fold_mu
}

## folded variance
folded_var <- function(mean, variance){
  mu <- mean
  sigma <- sqrt(variance)
  fold_mu <- sigma*sqrt(2/pi)*exp((-mu^2)/(2*sigma^2)) + mu*(1 - 2*pnorm(-mu/sigma))
  fold_se <- sqrt(mu^2 + sigma^2 - fold_mu^2)
  # variance
  fold_v <- fold_se^2
  fold_v
}


# alternatively
foldnorm <-  function(mu, var){
	   sd <- sqrt(var)
     postfnorm <- stats::dnorm(mu, 0, sd)*2*sd^2 + mu*(2*stats::pnorm(mu, 0, sd) -1)
		    est <- postfnorm
		    var.fnorm <- mu^2 + sd^2 - (sd*sqrt(2/pi)*exp((-1*mu^2)/(2*sd^2)) + mu*(1-2*stats::pnorm(-1*mu/sd, 0, 1)))^2
		    est <- data.frame(Mean=est, Variance = var.fnorm)
}
```

# Data

First, we load the dataset containing meta-analytic level effect sizes and standard errors.

```{r data}
# load meta-analyticlly derived estimates
df <- read.csv(here("Dat","est.csv"))
names(df)[3:7] <- c("mu_adj", "se_adj", "mu_unadj", "se_unadj", "discipline")
# calculate sampling variance of mu
df <- df %>% mutate(var_adj = se_adj^2,
                    var_unadj = se_unadj^2)
# adjust order
df <- df[c(1,2,5,6,9,3,4,8,7)]

# calculate two-sided p values based on standard normal distribution
df <- df %>% mutate(zval = mu_adj / se_adj,
                    pval = pnorm(abs(zval), lower.tail = F) * 2)




# load individual level estimates
datlist_eco <- readRDS(here("Dat/obs","dat_economics.RDS"))
datlist_env <- readRDS(here("Dat/obs","dat_environmental.RDS"))
datlist_med <- readRDS(here("Dat/obs","dat_medicine.RDS"))
datlist_psy <- readRDS(here("Dat/obs","dat_psychology.RDS"))
datlist_psy2 <- readRDS(here("Dat/obs","dat_psychology2.RDS"))
# convert into dataframes
dat_eco <- bind_rows(datlist_eco, .id = "source")
dat_env <- bind_rows(datlist_env, .id = "source")
dat_med <- bind_rows(datlist_med, .id = "source")
dat_psy <- bind_rows(c(datlist_psy,datlist_psy2), .id = "source")
# convert the effect size from z to d
dat_eco <- dat_eco %>% mutate(mu_obs = z2d(z),
                              se_obs = se_z2se_d(se_z = z.se, z = z))

dat_env <- dat_env %>% mutate(mu_obs = z2d(z),
                              se_obs = se_z2se_d(se_z = z.se, z = z))

dat_med <- dat_med %>% mutate(mu_obs = z2d(z),
                              se_obs = se_z2se_d(se_z = z.se, z = z))

dat_psy <- dat_psy %>% mutate(mu_obs = z2d(z),
                              se_obs = se_z2se_d(se_z = z.se, z = z))
```

# Magnitude

In terms of effect size benchmark, the sign of the effect size does not add any value. Therefore, we use the folded distribution (https://en.wikipedia.org/wiki/Folded_normal_distribution) to calculate the folded mean (the magnitude) and folded standard error. 

```{r folded}
# folded mean and error
df <- df %>% mutate(folded_mu_adj = folded_es(mu_adj, var_adj),
                    folded_var_adj = folded_var(mu_adj, var_adj))

# subsets
df_eco <- df %>% filter(discipline == "economics")
df_env <- df %>% filter(discipline == "environmental")
df_med <- df %>% filter(discipline == "medicine")
df_psy <- df %>% filter(discipline == "psychology")

# a quick look at the difference between different strategies
df %>%
  group_by(discipline) %>%
  summarize(Q1_un = quantile(abs(mu_unadj), probs = 0.25),
            Q1_abs = quantile(abs(mu_adj), probs = 0.25),
            Q1_fold = quantile(folded_mu_adj, probs = 0.25),
            median_un = quantile(abs(mu_unadj), probs = 0.50),
            median_abs = quantile(abs(mu_adj), probs = 0.50),
            median_fold = quantile(folded_mu_adj, probs = 0.50),
            mean_un = mean(abs(mu_unadj)),
            mean_abs = mean(abs(mu_adj)),
            mean_fold = mean(folded_mu_adj),
            Q3_un = quantile(abs(mu_unadj), probs = 0.75),
            Q3_abs = quantile(abs(mu_adj), probs = 0.75),
            Q3_fold = quantile(folded_mu_adj, probs = 0.75)) %>% knitr::kable(caption = 'Comparing different strategies', digits = 3)


# reference benchmark - using middle 40% of distribution (30th to 70th percentile)
df %>%
  group_by(discipline) %>%
  summarize(p30_ori = quantile(abs(mu_unadj), probs = 0.3),
            p30_abs = quantile(abs(mu_adj), probs = 0.3),
            p30_fold = quantile(folded_mu_adj, probs = 0.3),
            p70_ori = quantile(abs(mu_unadj), probs = 0.7),
            p70_abs = quantile(abs(mu_adj), probs = 0.7),
            p70_fold = quantile(folded_mu_adj, probs = 0.7)) %>% knitr::kable(caption = 'Comparing different strategies', digits = 3)



summary(df_eco$folded_mu_adj)
summary(filter(df_eco, pval<=0.05)$folded_mu_adj)

summary(df_env$folded_mu_adj)
summary(filter(df_env, pval<=0.05)$folded_mu_adj)

summary(df_med$folded_mu_adj)
summary(filter(df_med, pval<=0.05)$folded_mu_adj)


summary(df_psy$folded_mu_adj)
summary(filter(df_psy, pval<=0.05)$folded_mu_adj)

```

# Effect size benchmark

We have three ways to get the effect size benchmark.

## (1) Empirical density

The first way is to use the percentile of the empirical density of meta-analytic level effect size estimates.

### Visualization

```{r}

#*************************************************#
#*--------------------economic-------------------#
#*************************************************#

# individual vs. meta-analytic
# prepare data
dat_long <- data.frame(Approach = c(rep("Individual", nrow(dat_eco)), rep("Meta-analytical", nrow(df_eco))),
                  Estimate = c(dat_eco$mu_obs, df_eco$mu_adj))


# plot
dat_long$Approach <- as.factor(dat_long$Approach)
dat_long$Approach <- factor(dat_long$Approach, levels = c("Individual", "Meta-analytical"))

# https://rpkgs.datanovia.com/ggpubr/reference/ggdensity.html
p.den_eco <- ggdensity(dat_long, x = "Estimate",
   add = "none", rug = TRUE, alpha = 0.4,
   color = "Approach", fill = "Approach",
   palette = c("#5867AF", "#F1AEA7")) + 
  labs(title = "Economics", x = "Effect size estimate", y = "Density", fill = "", color = "") +
  theme(axis.line.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.text.y = element_blank(),
        axis.title.y = element_blank()) + 
  xlim(-3,3)




# original vs. adjusted
# prepare data
dat <- select(df_eco, id, mu_unadj, mu_adj, folded_mu_adj)
dat_long <- dat %>%
  pivot_longer(cols = c(mu_unadj, mu_adj), 
               names_to = "Approach", 
               values_to = "Estimate") %>%
  mutate(Approach = recode(Approach, 
                       mu_unadj = "Original", 
                       mu_adj = "Adjusted"))
# plot
dat_long$Approach <- as.factor(dat_long$Approach)
dat_long$Approach <- factor(dat_long$Approach, levels = c("Original", "Adjusted"))

# https://rpkgs.datanovia.com/ggpubr/reference/ggdensity.html
p.den_eco2 <- ggdensity(dat_long, x = "Estimate",
   add = "none", rug = TRUE, alpha = 0.4,
   color = "Approach", fill = "Approach",
   palette = c("#FCB462", "#7BC4C5")) + 
  labs(title = "Economics", x = "Meta-analytically derived effect", y = "Density", fill = "", color = "") +
  theme(axis.line.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.text.y = element_blank(),
        axis.title.y = element_blank())


# absolute vs. folded
dat_long <- dat %>%
  pivot_longer(cols = c(mu_adj, folded_mu_adj), 
               names_to = "Approach", 
               values_to = "Estimate") %>%
  mutate(Approach = recode(Approach, 
                       mu_adj = "Absolute", 
                       folded_mu_adj = "Folded"))
# plot
dat_long$Approach <- as.factor(dat_long$Approach)
dat_long$Approach <- factor(dat_long$Approach, levels = c("Absolute", "Folded"))
dat_long$Estimate <- abs(dat_long$Estimate)

p.den_eco3 <- ggdensity(dat_long, x = "Estimate",
   add = "none", rug = TRUE, alpha = 0.4,
   color = "Approach", fill = "Approach",
   palette = c("#8CA5EA", "#E3738B")) +
  labs(title = "Economics", x = "Meta-analytically derived effect", y = "Density", fill = "", color = "") +
  theme(axis.line.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.text.y = element_blank(),
        axis.title.y = element_blank())


png(filename = "Fig.density_eco.png", width = 6, height = 12, units = "in", type = "windows", res = 400)
p.den_eco / p.den_eco2 / p.den_eco3
dev.off()

#*************************************************#
#*--------------------environment-------------------#
#*************************************************#

# prepare data
dat <- select(df_env, id, mu_unadj, mu_adj, folded_mu_adj)

# original vs. adjusted
dat_long <- dat %>%
  pivot_longer(cols = c(mu_unadj, mu_adj), 
               names_to = "Approach", 
               values_to = "Estimate") %>%
  mutate(Approach = recode(Approach, 
                       mu_unadj = "Original", 
                       mu_adj = "Adjusted"))
# plot
dat_long$Approach <- as.factor(dat_long$Approach)
dat_long$Approach <- factor(dat_long$Approach, levels = c("Original", "Adjusted"))

p.den_env <- ggdensity(dat_long, x = "Estimate",
   add = "none", rug = TRUE, alpha = 0.4,
   color = "Approach", fill = "Approach",
   palette = c("#FCB462", "#7BC4C5")) + 
  labs(title = "Environment", x = "Meta-analytic effect size estimate", y = "Density", fill = "", color = "") +
  theme(axis.line.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.text.y = element_blank(),
        axis.title.y = element_blank())


# absolute vs. folded
dat_long <- dat %>%
  pivot_longer(cols = c(mu_adj, folded_mu_adj), 
               names_to = "Approach", 
               values_to = "Estimate") %>%
  mutate(Approach = recode(Approach, 
                       mu_adj = "Absolute", 
                       folded_mu_adj = "Folded"))
# plot
dat_long$Approach <- as.factor(dat_long$Approach)
dat_long$Approach <- factor(dat_long$Approach, levels = c("Absolute", "Folded"))
dat_long$Estimate <- abs(dat_long$Estimate)

p.den_env2 <- ggdensity(dat_long, x = "Estimate",
   add = "none", rug = TRUE, alpha = 0.4,
   color = "Approach", fill = "Approach",
   palette = c("#8CA5EA", "#E3738B")) +
  labs(title = "Environment", x = "Meta-analytic effect size estimate", y = "Density", fill = "", color = "") +
  theme(axis.line.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.text.y = element_blank(),
        axis.title.y = element_blank())


png(filename = "Fig.density_env.png", width = 10, height = 6, units = "in", type = "windows", res = 400)
p.den_env | p.den_env2
dev.off()


#*************************************************#
#*--------------------psychology-------------------#
#*************************************************#

# prepare data
dat <- select(df_psy, id, mu_unadj, mu_adj, folded_mu_adj)

# original vs. adjusted
dat_long <- dat %>%
  pivot_longer(cols = c(mu_unadj, mu_adj), 
               names_to = "Approach", 
               values_to = "Estimate") %>%
  mutate(Approach = recode(Approach, 
                       mu_unadj = "Original", 
                       mu_adj = "Adjusted"))
# plot
dat_long$Approach <- as.factor(dat_long$Approach)
dat_long$Approach <- factor(dat_long$Approach, levels = c("Original", "Adjusted"))

p.den_psy <- ggdensity(dat_long, x = "Estimate",
   add = "none", rug = TRUE, alpha = 0.4,
   color = "Approach", fill = "Approach",
   palette = c("#FCB462", "#7BC4C5")) + 
  labs(title = "Psychology", x = "Meta-analytic effect size estimate", y = "Density", fill = "", color = "") +
  theme(axis.line.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.text.y = element_blank(),
        axis.title.y = element_blank())


# absolute vs. folded
dat_long <- dat %>%
  pivot_longer(cols = c(mu_adj, folded_mu_adj), 
               names_to = "Approach", 
               values_to = "Estimate") %>%
  mutate(Approach = recode(Approach, 
                       mu_adj = "Absolute", 
                       folded_mu_adj = "Folded"))
# plot
dat_long$Approach <- as.factor(dat_long$Approach)
dat_long$Approach <- factor(dat_long$Approach, levels = c("Absolute", "Folded"))
dat_long$Estimate <- abs(dat_long$Estimate)

p.den_psy2 <- ggdensity(dat_long, x = "Estimate",
   add = "none", rug = TRUE, alpha = 0.4,
   color = "Approach", fill = "Approach",
   palette = c("#8CA5EA", "#E3738B")) +
  labs(title = "Psychology", x = "Meta-analytic effect size estimate", y = "Density", fill = "", color = "") +
  theme(axis.line.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.text.y = element_blank(),
        axis.title.y = element_blank())


png(filename = "Fig.density_psy.png", width = 10, height = 6, units = "in", type = "windows", res = 400)
p.den_psy | p.den_psy2
dev.off()

#*************************************************#
#*--------------------medicine-------------------#
#*************************************************#

# prepare data
dat <- select(df_med, id, mu_unadj, mu_adj, folded_mu_adj)

# original vs. adjusted
dat_long <- dat %>%
  pivot_longer(cols = c(mu_unadj, mu_adj), 
               names_to = "Approach", 
               values_to = "Estimate") %>%
  mutate(Approach = recode(Approach, 
                       mu_unadj = "Original", 
                       mu_adj = "Adjusted"))
# plot
dat_long$Approach <- as.factor(dat_long$Approach)
dat_long$Approach <- factor(dat_long$Approach, levels = c("Original", "Adjusted"))

p.den_med <- ggdensity(dat_long, x = "Estimate",
   add = "none", rug = TRUE, alpha = 0.4,
   color = "Approach", fill = "Approach",
   palette = c("#FCB462", "#7BC4C5")) + 
  labs(title = "Medicine", x = "Meta-analytic effect size estimate", y = "Density", fill = "", color = "") +
  theme(axis.line.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.text.y = element_blank(),
        axis.title.y = element_blank())


# absolute vs. folded
dat_long <- dat %>%
  pivot_longer(cols = c(mu_adj, folded_mu_adj), 
               names_to = "Approach", 
               values_to = "Estimate") %>%
  mutate(Approach = recode(Approach, 
                       mu_adj = "Absolute", 
                       folded_mu_adj = "Folded"))
# plot
dat_long$Approach <- as.factor(dat_long$Approach)
dat_long$Approach <- factor(dat_long$Approach, levels = c("Absolute", "Folded"))
dat_long$Estimate <- abs(dat_long$Estimate)

p.den_med2 <- ggdensity(dat_long, x = "Estimate",
   add = "none", rug = TRUE, alpha = 0.4,
   color = "Approach", fill = "Approach",
   palette = c("#8CA5EA", "#E3738B")) +
  labs(title = "Medicine", x = "Meta-analytic effect size estimate", y = "Density", fill = "", color = "") +
  theme(axis.line.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.text.y = element_blank(),
        axis.title.y = element_blank())

png(filename = "Fig.density_psy.png", width = 10, height = 6, units = "in", type = "windows", res = 400)
p.den_med | p.den_med2
dev.off()

# assembly
png(filename = "Fig.density.png", width = 12, height = 12, units = "in", type = "windows", res = 400)
  p.den_psy + p.den_psy2 +
  p.den_med + p.den_med2 +
  p.den_eco + p.den_eco2 +
  p.den_env + p.den_env2 +
  plot_layout(nrow = 4, ncol = 2) + plot_annotation(tag_levels = list(c('A', 'B', 'C', 'D', 'E', 'F', 'G', 'H'))) & theme(plot.tag = element_text(size = 18, face = "bold"))
dev.off()
```


For economics:

```{r empirical density}
quantile(df_eco$folded_mu_adj, probs = c(.25, .5, .75))
```

For environment:

```{r}
quantile(df_env$folded_mu_adj, probs = c(.25, .5, .75))
```

For psychology:

```{r}
quantile(df_psy$folded_mu_adj, probs = c(.25, .5, .75))
```

For medicine:

```{r empirical Bayes}
quantile(df_med$folded_mu_adj, probs = c(.25, .5, .75))
```



## (2) Empirical Bayes

```{r}
library(metaSEM)
res_med2 <- metaSEM::meta(y=mu_adj, v=se_adj^2, data=dat_med)
```



earlier attempt:
```{r}
res_eco <- meta(y=folded_mu_adj, v=folded_var_adj, data = df_eco)
# use metafor to validate the model estimates from metaSEM - perfectly match
#res_eco2 <- rma(yi = folded_mu_adj, vi = folded_var_adj, data = df_eco)
library(EnvStats)
res_eco_r <- rnormTrunc(1e5, mean = coef(res_eco)[1], sd = sqrt(coef(res_eco)[2]), min = 0)
# percentile
quantile(res_eco_r, probs = seq(0.1, 1, by = 0.1)) %>% round(4)
quantile(df_eco$folded_mu_adj, probs = seq(0.1, 1, by = 0.1)) %>% round(4)

```


```{r}
res_env <- meta(y=folded_mu_adj, v=folded_var_adj, data = df_env)
res_env_r <- rnorm(1e5, mean = coef(res_env)[1], sd = sqrt(coef(res_env)[2]))
# percentile
quantile(res_env_r, probs = seq(0.1, 1, by = 0.1)) %>% round(4)

```


## (3) Posterior distribution

The third way is to estimate the posterior distribution (empirical Bayes estimates) and get the percentiles. This should be affect by the prior. I am not sure which priors we would use. I think you will know more than me. So I leave this section to you.


# Interpretation

I want to have a package to help users to automate the interpretation. My idea is to use the equivalence test to compare whether a given meta-analytic mean is equivalent to a threshold (benchmark) derived from the above three ways.

For example, assume we use 25-th, 50-th, and 75-th percentiles of economic effect sizes as the small, medium and large magnitude. Now, we conduct a meta-analysis and we get a point estimate of 0.18 and standard error 0.1. We want to know whether this point effect is equivalent to the medium threshold in the field of economics.


This can be done by: 
```{r equivalence}
library("TOSTER")
TOSTmeta(ES = 0.25, se = 0.08, low_eqbound_d = - quantile(blup_eco$pred, probs = c(.25, .5, .75))[2], high_eqbound_d = quantile(blup_eco$pred, probs = c(.25, .5, .75))[2], alpha = 0.05)
```

We see that although the magnitude of the effect size (0.25) is larger than the 75-th percentile (0.2094795), it's magnitude is equivalent to the 50-th percentile (0.12798826), if considering the uncertainty. 



# Additional: Distribution of empirical Bayes estimates
The second way is to calculate the empirical Bayes (or best linear unbiased prediction) corresponding to each meta-analytic level effect size and then use percentile of the empirical density of the empirical Bayes. By empirical Bayes, I mean the meta-analytic specific true effect size after borrowing strength (partial pooling in the context of multilevel model).

To do so, we: (1) fit a random-effect model to account for the second-order sampling error, (2) calculate the Best linear unbiased prediction.

First let's get the empirical Bayes for each discipline.

```{r}
#---------------------------------------------------#
#empirical Bayes
#---------------------------------------------------#

#------------------economics------------------#
res_eco <- meta(y = folded_mu_adj, v = folded_var_adj, data = df_eco)
df_eco <- df_eco %>% mutate(lamda = coef(res_eco)[2] / (coef(res_eco)[2] + df_eco$folded_var_adj),
                            blup = lamda * df_eco$folded_mu_adj + (1 - lamda) * coef(res_eco)[1])

# manual validation
res_eco <- rma(yi = folded_mu_adj, vi= folded_var_adj, method = "REML", data = df_eco)
# get Empirical Bayes
blup_eco <- blup(res_eco) %>% as.data.frame()
# manual computation of blup
blup_eco <- blup_eco %>% mutate(lamda = res_eco$tau2 / (res_eco$tau2 + res_eco$vi),
                                pred2 = lamda * res_eco$yi + (1 - lamda) * res_eco$beta[1])

#------------------environment------------------#
res_env <- meta(y = folded_mu_adj, v = folded_var_adj, data = df_env)
df_env <- df_env %>% mutate(lamda = coef(res_env)[2] / (coef(res_env)[2] + df_env$folded_var_adj),
                            blup = lamda * df_env$folded_mu_adj + (1 - lamda) * coef(res_env)[1])


#------------------psychology------------------#
res_psy <- meta(y = folded_mu_adj, v = folded_var_adj, data = df_psy)
df_psy <- df_psy %>% mutate(lamda = coef(res_psy)[2] / (coef(res_psy)[2] + df_psy$folded_var_adj),
                            blup = lamda * df_psy$folded_mu_adj + (1 - lamda) * coef(res_psy)[1])



#------------------medicine------------------#
res_med <- meta(y = folded_mu_adj, v = folded_var_adj, data = df_med)
df_med <- df_med %>% mutate(lamda = coef(res_med)[2] / (coef(res_med)[2] + df_med$folded_var_adj),
                            blup = lamda * df_med$folded_mu_adj + (1 - lamda) * coef(res_med)[1])

# rma (and rma.mv) does not allow for a meta-analysis with a large number of sample size due to k*k matrix multiplication, therefore, we split the dataset of medicine into 6 subsets

# I upload pre-fitted model to save time

res_med1 <- readRDS(here("Dat","res_med1.rds"))
blup_med1 <- blup(res_med1) %>% as.data.frame()

# res_med1 <- res_med <- rma(yi = folded_mu_adj, vi= folded_var_adj, method = "REML", data = df_med[1:10000,])
#saveRDS(res_med1, here("es_benchmark/es_benchmark_git/Dat","res_med1.rds"))
# second 10000
res_med2 <- readRDS(here("Dat","res_med2.rds"))
blup_med2 <- blup(res_med2) %>% as.data.frame()
#res_med2 <- res_med <- rma(yi = folded_mu_adj, vi= folded_var_adj, method = "REML", data = df_med[10001:20000,])
#saveRDS(res_med2, here("es_benchmark/es_benchmark_git/Dat","res_med2.rds"))
# third 10000
res_med3 <- readRDS(here("Dat","res_med3.rds"))
blup_med3 <- blup(res_med3) %>% as.data.frame()
#res_med3 <- res_med <- rma(yi = folded_mu_adj, vi= folded_var_adj, method = "REML", data = df_med[20001:30000,])
#saveRDS(res_med3, here("es_benchmark/es_benchmark_git/Dat","res_med3.rds"))
# fourth 10000
res_med4 <- readRDS(here("Dat","res_med4.rds"))
blup_med4 <- blup(res_med4) %>% as.data.frame()
#res_med4 <- res_med <- rma(yi = folded_mu_adj, vi= folded_var_adj, method = "REML", data = df_med[30001:40000,])
#saveRDS(res_med4, here("es_benchmark/es_benchmark_git/Dat","res_med4.rds"))
# fifth 10000
res_med5 <- readRDS(here("Dat","res_med5.rds"))
blup_med5 <- blup(res_med5) %>% as.data.frame()
#res_med5 <- res_med <- rma(yi = folded_mu_adj, vi= folded_var_adj, method = "REML", data = df_med[40001:50000,])
#saveRDS(res_med5, here("es_benchmark/es_benchmark_git/Dat","res_med5.rds"))
# the rest
res_med6 <- readRDS(here("Dat","res_med6.rds"))
blup_med6 <- blup(res_med6) %>% as.data.frame()
#res_med6 <- res_med <- rma(yi = folded_mu_adj, vi= folded_var_adj, method = "REML", data = df_med[50001:nrow(df_med),])
#saveRDS(res_med6, here("es_benchmark/es_benchmark_git/Dat","res_med6.rds"))
# combine
blup_med <- rbind(blup_med1, blup_med2, blup_med3, blup_med4, blup_med5, blup_med6)
```

Then, we calculate the percentiles of the empirical Bayes.

For economics:

```{r}
quantile(blup_eco$pred, probs = seq(0.1,1,by=0.1)) %>% round(3)
quantile(df_eco$folded_mu_adj, probs = seq(0.1,1,by=0.1)) %>% round(3)
```

For environment:

```{r}
quantile(blup_env$pred, probs = c(.25, .5, .75))
```

For psychology:

```{r}
quantile(blup_psy$pred, probs = c(.25, .5, .75))
```

For medicine:

```{r}
quantile(df_med$eb, probs = seq(0.1,1,by=0.1)) %>% round(3)
quantile(df_med$folded_mu_adj, probs = seq(0.1,1,by=0.1)) %>% round(3)
```

We see that the percentiles of different disciplines are quite different. The percentiles of medicine seem to be a bit weird.


# test of difference between distributions

https://stats.stackexchange.com/questions/52305/comparison-of-2-distributions/52329#52329

implementation:
https://stat.ethz.ch/R-manual/R-patched/library/stats/html/ks.test.html

good explanations:
https://towardsdatascience.com/how-to-compare-two-distributions-in-practice-8c676904a285

https://stats.stackexchange.com/questions/4/assessing-the-significance-of-differences-in-distributions

https://stats.stackexchange.com/questions/9311/kullback-leibler-vs-kolmogorov-smirnov-distance

pvalue of the KS test: https://stats.stackexchange.com/questions/149595/ks-test-how-is-the-p-value-calculated


Bootstrapping based on the Kolmogorov-Smirnov test
https://cran.r-project.org/web/packages/kldtools/kldtools.pdf

```{r}
library(dgof)

dgof::ks.test(filter(dat_long, Approach == "Individual")$Estimate, filter(dat_long, Approach == "Meta-analytical")$Estimate)


# two-samples ks.test will silently resort to approximation when the product of the two sample sizes is larger than 10,000.
# solution: https://github.com/franapoli/signed-ks-test

library(kldtools)
ksboot(filter(dat_long, Approach == "Individual")$Estimate, filter(dat_long, Approach == "Meta-analytical")$Estimate)
```


# bootstrap confidence intervals for distribution properities

https://cran.r-project.org/web/packages/confintr/vignettes/confintr.html

https://cran.r-project.org/web/packages/DescTools/DescTools.pdf

```{r}
library(confintr)
x <- 1:200
ci_skewness(x, R = 999)
ci_kurtosis(x, R = 999)

library(DescTools) 
# point estimate plus bootstrap CIs
Skew(x, na.rm=TRUE, conf.level = 0.95)
Kurt(x, na.rm=TRUE, conf.level = 0.95)

```

# Formula for folded mean and variance
https://search.r-project.org/CRAN/refmans/greybox/html/FNormal.html

https://en.wikipedia.org/wiki/Folded_normal_distribution

https://search.r-project.org/CRAN/refmans/VGAM/html/foldnormal.html

```{r}

```


# Check if a distribution is unimodal or multimodal

https://search.r-project.org/CRAN/refmans/performance/html/check_multimodal.html

https://universeofdatascience.com/how-to-determine-if-data-are-unimodal-or-multimodal-in-r/

# mixture model and likelihood ratio test
https://stats.stackexchange.com/questions/138223/how-to-test-if-my-distribution-is-multimodal
https://stats.stackexchange.com/questions/51062/test-for-bimodal-distribution

```{r}
library(performance)
check_multimodal(df_psy$mu_adj)


library(LaplacesDemon)
LaplacesDemon::is.bimodal(df_med$mu_adj)
LaplacesDemon::is.bimodal(df_env$mu_adj)

LaplacesDemon::is.trimodal(df_env$mu_adj)



library(diptest)
dip.test(df_med$mu_adj)
```



# Ask:


```{r}

library(metafor)
dat <- dat.bangertdrowns2004
# fit a RE
res <- rma(yi, vi, data=dat)
# get shrinkage
dat$lamda <- res$tau2 / (res$tau2 + res$vi)
# get study-specific effect
dat$theta <- dat$lamda * res$yi + (1 - dat$lamda) * res$beta[1]
# use blup() to get theta 
theta <- blup(res)
# manual check
dat$theta == theta$pred

# fit the same RE as a location-scale model
res.ls <- rma(yi, vi, scale = ~ 1, data=dat)

```

