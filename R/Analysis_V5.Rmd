---
title: "Effect size benchmarks and guidelines: approaches, interpretation, and applications"
header-includes: \usepackage{amsmath}
output:
  html_document:
    toc: yes
    toc_depth: '2'
    df_print: paged
  pdf_document:
    toc: yes
    toc_depth: 2
    number_sections: yes
    keep_tex: no
---

# Introduction

Our aim is to provide the empirical effect size benchmark using publication-bias adjusted meta-analytic mean effects. This is meaningful, although people would argue that the interpretation of effect size is dependent on the research question at hand.

The existing effect size benchmark has four issues:

(1) Cohen's benchmark is basically based on his intuition and not evidence-based;

(2) Some researchers provide empirical benchmarks, but they do not account for publication bias;

(3) The simple use of absolute value of the effect size overlooks the  distributional properties (e.g., shape and skewness);

(4) When users interpret the magnitude of effect size, they ignore the sampling variance around the estimation.

# Packages

```{r package, warning=FALSE, echo=TRUE}
set.seed(2024)
suppressPackageStartupMessages({
  library(dplyr)
  library(readr)
  library(tidyr) 
  library(here)
  library(ggplot2)
  library(ggpubr)
  library(metafor)
  library(metaSEM)
  library(cowplot)
  library(car)
  library(kldtools)
  library(patchwork)
  library(RoBMA)
  library(boot)
  library(diptest)
  library(LaplacesDemon)
  library(moments)}
  )
# custom functions
source(here("Func","func.R"))
```

# Benchmark approaches

We have four ways to derive the effect size benchmarks. We also conduct a sensitivity analysis to test the robustness of the preferred approach.

## (1) Individual level effect size estimates

The first way is to use the percentile of the empirical density of meta-analytic level effect size estimates. In total, we collected 725,436 individual level effect size estimates (details see main text).

```{r}
# load individual level estimates
datlist_eco <- readRDS(here("Dat/obs","dat_economics.RDS"))
datlist_env <- readRDS(here("Dat/obs","dat_environmental.RDS"))
datlist_med <- readRDS(here("Dat/obs","dat_medicine.RDS"))
datlist_psy <- readRDS(here("Dat/obs","dat_psychology.RDS"))
datlist_psy2 <- readRDS(here("Dat/obs","dat_psychology2.RDS"))
# convert into dataframes
dat_eco <- bind_rows(datlist_eco, .id = "source")
dat_env <- bind_rows(datlist_env, .id = "source")
dat_med <- bind_rows(datlist_med, .id = "source")
dat_psy <- bind_rows(c(datlist_psy,datlist_psy2), .id = "source")
# convert the effect size from z to d
dat_eco <- dat_eco %>% mutate(mu_obs = z2d(z),
                              se_obs = se_z2se_d(se_z = z.se, z = z))

dat_env <- dat_env %>% mutate(mu_obs = z2d(z),
                              se_obs = se_z2se_d(se_z = z.se, z = z))

dat_med <- dat_med %>% mutate(mu_obs = z2d(z),
                              se_obs = se_z2se_d(se_z = z.se, z = z))

dat_psy <- dat_psy %>% mutate(mu_obs = z2d(z),
                              se_obs = se_z2se_d(se_z = z.se, z = z))
```


## (2) Unadjusted (naïve) meta-analytic level effect size estimates

The second approach is based on the distribution of unadjusted (naïve) meta-analytic level effect size estimates. To be more precise, these unadjusted estimates are just those derived from normal meta-analysis models without using any publication bias correction. The variables `mu_unadj` and `se_unadj` in the dataset `df` (see the below code chunk) represent the point estimate of unadjusted meta-analytic level effect size and its standard error, respectively.

```{r}
# load meta-analytically derived estimates
df <- read.csv(here("Dat","est.csv"))
names(df)[3:7] <- c("mu_adj", "se_adj", "mu_unadj", "se_unadj", "discipline")
# study info
studies_info <- readRDS(here("Dat","studies_info.RDS"))

# calculate sampling variance of mu
df <- df %>% mutate(var_adj = se_adj^2,
                    var_unadj = se_unadj^2)
# adjust order
df <- df[c(1,2,5,6,9,3,4,8,7)]

# calculate two-sided p values based on standard normal distribution
df <- df %>% mutate(zval = mu_adj / se_adj,
                    pval = pnorm(abs(zval), lower.tail = F) * 2)
```

## (3) Adjusted meta-analytic level effect size estimates

The third approach is based on the distribution of adjusted meta-analytic level effect size estimates. These were obtained using robust Bayesian meta-analysis (RoBMA-PSMA). We employed the RoBMA-PSMA model assuming presence of the effect which aggregates over 18 meta-analytic models; all combinations of models assuming presence vs. absence of heterogeneity and models assuming presence vs. absence of publication bias. A brief summary of the technique can be found in the main text. For those interested in the technical details, please refer to Bartoš et al., (2024) and Maier et al., (2023). The corresponding R code for reproducing the adjusted meta-analytic level effect size estimates used in our study is available at Bartoš et al., (2024). To avoid repeats, we did not show the code for this part. The variables `mu_adj` and `se_adj` in the dataset `df` represent the point estimate of adjusted meta-analytic level effect size and its standard error, respectively.


## (4) Adjusted and folded meta-analytic level effect size estimates

The fourth approach is the preferred approach, which is based on the folded distribution of adjusted meta-analytic level effect size estimates. In terms of effect size benchmark, the sign of the effect size add zero value. Therefore, we use the folded distribution to calculate the folded mean (the magnitude) and folded standard error. Refer to the main text for some technical details and explanations.

```{r}
# folded mean and error
df <- df %>% mutate(folded_mu_adj = folded_es(mu_adj, var_adj),
                    folded_var_adj = folded_var(mu_adj, var_adj))

# subsets
df_eco <- df %>% filter(discipline == "economics")
df_env <- df %>% filter(discipline == "environmental")
df_med <- df %>% filter(discipline == "medicine")
df_psy <- df %>% filter(discipline == "psychology")

# a quick look at the difference between different strategies
df %>%
  group_by(discipline) %>%
  summarize(Q1_un = quantile(abs(mu_unadj), probs = 0.25),
            Q1_abs = quantile(abs(mu_adj), probs = 0.25),
            Q1_fold = quantile(folded_mu_adj, probs = 0.25),
            median_un = quantile(abs(mu_unadj), probs = 0.50),
            median_abs = quantile(abs(mu_adj), probs = 0.50),
            median_fold = quantile(folded_mu_adj, probs = 0.50),
            mean_un = mean(abs(mu_unadj)),
            mean_abs = mean(abs(mu_adj)),
            mean_fold = mean(folded_mu_adj),
            Q3_un = quantile(abs(mu_unadj), probs = 0.75),
            Q3_abs = quantile(abs(mu_adj), probs = 0.75),
            Q3_fold = quantile(folded_mu_adj, probs = 0.75)) %>% knitr::kable(caption = 'Comparing different strategies', digits = 3)



# reference benchmark - using middle 40% of distribution (30th to 70th percentile)
df %>%
  group_by(discipline) %>%
  summarize(p30_ori = quantile(abs(mu_unadj), probs = 0.3),
            p30_abs = quantile(abs(mu_adj), probs = 0.3),
            p30_fold = quantile(folded_mu_adj, probs = 0.3),
            p70_ori = quantile(abs(mu_unadj), probs = 0.7),
            p70_abs = quantile(abs(mu_adj), probs = 0.7),
            p70_fold = quantile(folded_mu_adj, probs = 0.7)) %>% knitr::kable(caption = 'Comparing different strategies', digits = 3)
```

## (5) Sensitivity analysis: Empirical Bayes

We also conduct a sensitivity analysis to test the robustness of the effect size benchmarks based on the adjusted and folded meta-analytic level effect size estimates. We calculate the empirical Bayes (or best linear unbiased prediction) corresponding to each meta-analytic level effect size and then use percentile of the empirical density of the empirical Bayes. By empirical Bayes, we mean the meta-analytic specific true effect size after borrowing strength (partial pooling in the context of multilevel model). This is a way to account for second-order sampling error.


```{r}
#---------------------------------------------------#
# empirical Bayes
#---------------------------------------------------#

#------------------economics------------------#
res_eco <- meta(y = folded_mu_adj, v = folded_var_adj, data = df_eco)
df_eco <- df_eco %>% mutate(lamda = coef(res_eco)[2] / (coef(res_eco)[2] + df_eco$folded_var_adj),
                            blup = lamda * df_eco$folded_mu_adj + (1 - lamda) * coef(res_eco)[1])

# manual validation
res_eco2 <- rma(yi = folded_mu_adj, vi= folded_var_adj, method = "REML", data = df_eco)
# get Empirical Bayes
blup_eco <- blup(res_eco2) %>% as.data.frame()
# manual computation of blup
blup_eco <- blup_eco %>% mutate(lamda = res_eco2$tau2 / (res_eco2$tau2 + res_eco2$vi),
                                pred2 = lamda * res_eco2$yi + (1 - lamda) * res_eco2$beta[1])

df_eco2 <- df_eco %>% mutate(blup2 = blup_eco$pred,
                             blup3 = blup_eco$pred2)


# example data from metadata
dat <- escalc(measure="RR", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)
res <- rma(yi, vi, data=dat)
blup_res <- blup(res) %>% as.data.frame()
blup_res <- blup_res %>% mutate(lamda = res$tau2 / (res$tau2 + res$vi),
                                pred2 = lamda * res$yi + (1 - lamda) * res$beta[1])

#------------------environment------------------#
res_env <- meta(y = folded_mu_adj, v = folded_var_adj, data = df_env)
df_env <- df_env %>% mutate(lamda = coef(res_env)[2] / (coef(res_env)[2] + df_env$folded_var_adj),
                            blup = lamda * df_env$folded_mu_adj + (1 - lamda) * coef(res_env)[1])


#------------------psychology------------------#
res_psy <- meta(y = folded_mu_adj, v = folded_var_adj, data = df_psy)
df_psy <- df_psy %>% mutate(lamda = coef(res_psy)[2] / (coef(res_psy)[2] + df_psy$folded_var_adj),
                            blup = lamda * df_psy$folded_mu_adj + (1 - lamda) * coef(res_psy)[1])



#------------------medicine------------------#
res_med <- meta(y = folded_mu_adj, v = folded_var_adj, data = df_med)
df_med <- df_med %>% mutate(lamda = coef(res_med)[2] / (coef(res_med)[2] + df_med$folded_var_adj),
                            blup = lamda * df_med$folded_mu_adj + (1 - lamda) * coef(res_med)[1])

#saveRDS(res_med1, here("es_benchmark/es_benchmark_git/Dat","res_med1.rds"))
# res_med1 <- readRDS(here("Dat","res_med1.rds"))
```


# Scale-related tests

We used a couple of typical statistical test to examine the variances (scale parameters) of the effect size distributions obtained from different approaches.

## F-test

We use F-test to statistically compare the equality of two variances of two distributions. The test statistic, random variable F, is used to determine if the tested data has an F-distribution under the true null hypothesis, and true customary assumptions about the error term.

```{r}
#------------------economics------------------#
Ftest_eco <- var.test(dat_eco$mu_obs, df_eco$mu_unadj)
Ftest_eco2 <- var.test(df_eco$mu_unadj, df_eco$mu_adj)
Ftest_eco3 <- var.test(abs(df_eco$mu_adj), df_eco$folded_mu_adj)
Ftest_eco4 <- var.test(df_eco$folded_mu_adj, df_eco$blup)

#------------------environment------------------#
Ftest_env <- var.test(dat_env$mu_obs, df_env$mu_unadj)
Ftest_env2 <- var.test(df_env$mu_unadj, df_env$mu_adj)
Ftest_env3 <- var.test(abs(df_env$mu_adj), df_env$folded_mu_adj)
Ftest_env4 <- var.test(df_env$folded_mu_adj, df_env$blup)


#------------------medicine------------------#
Ftest_med <- var.test(dat_med$mu_obs, df_med$mu_unadj)
Ftest_med2 <- var.test(df_med$mu_unadj, df_med$mu_adj)
Ftest_med3 <- var.test(abs(df_med$mu_adj), df_med$folded_mu_adj)
Ftest_med4 <- var.test(df_med$folded_mu_adj, df_med$blup)


#------------------psychology------------------#
Ftest_psy <- var.test(dat_psy$mu_obs, df_psy$mu_unadj)
Ftest_psy2 <- var.test(df_psy$mu_unadj, df_psy$mu_adj)
Ftest_psy3 <- var.test(abs(df_psy$mu_adj), df_psy$folded_mu_adj)
Ftest_psy4 <- var.test(df_psy$folded_mu_adj, df_psy$blup)
```

## Fligner-Killeen test

We also perform Fligner-Killeen variance homogeneity test, a non-parametric test which is very robust against departures from normality.

```{r}
#------------------economics------------------#
dat_long_eco <- data.frame(Approach = c(rep("Individual level", nrow(dat_eco)), rep("Meta-analytic", nrow(df_eco))),
                           Estimate = c(dat_eco$mu_obs, df_eco$mu_adj))
fligner_eco <- fligner.test(Estimate ~ as.factor(Approach), data = dat_long_eco)

#------------------environment------------------#
dat_long_env <- data.frame(Approach = c(rep("Individual level", nrow(dat_env)), rep("Meta-analytic", nrow(df_env))),
                           Estimate = c(dat_env$mu_obs, df_env$mu_adj))
fligner_env <- fligner.test(Estimate ~ as.factor(Approach), data = dat_long_env)

#------------------medicine------------------#
dat_long_med <- data.frame(Approach = c(rep("Individual level", nrow(dat_med)), rep("Meta-analytic", nrow(df_med))),
                           Estimate = c(dat_med$mu_obs, df_med$mu_adj))
fligner_med <- fligner.test(Estimate ~ as.factor(Approach), data = dat_long_med)

#------------------psychology------------------#
dat_long_psy <- data.frame(Approach = c(rep("Individual level", nrow(dat_psy)), rep("Meta-analytic", nrow(df_psy))),
                           Estimate = c(dat_psy$mu_obs, df_psy$mu_adj))
fligner_psy <- fligner.test(Estimate ~ as.factor(Approach), data = dat_long_psy)
```


# Location-related tests

## Mann-Whitney U test

We used Wilcoxon rank-sum test, a nonparametric statistical test of the shift in location of probability distribution.

```{r}
#------------------economics------------------# 
wilcox_eco <- wilcox.test(dat_eco$mu_obs, df_eco$mu_unadj)
wilcox_eco2 <- wilcox.test(df_eco$mu_unadj, df_eco$mu_adj)
wilcox_eco3 <- wilcox.test(abs(df_eco$mu_adj), df_eco$folded_mu_adj)


#------------------environment------------------#
wilcox_env <- wilcox.test(dat_env$mu_obs, df_env$mu_unadj)
wilcox_env2 <- wilcox.test(df_env$mu_unadj, df_env$mu_adj)
wilcox_env3 <- wilcox.test(abs(df_env$mu_adj), df_env$folded_mu_adj)

#------------------medicine------------------#
wilcox_med <- wilcox.test(dat_med$mu_obs, df_med$mu_unadj)
wilcox_med2 <- wilcox.test(df_med$mu_unadj, df_med$mu_adj)
wilcox_med3 <- wilcox.test(abs(df_med$mu_adj), df_med$folded_mu_adj)


#------------------psychology------------------#
wilcox_psy <- wilcox.test(dat_psy$mu_obs, df_psy$mu_unadj)
wilcox_psy2 <- wilcox.test(df_psy$mu_unadj, df_psy$mu_adj)
wilcox_psy3 <- wilcox.test(abs(df_psy$mu_adj), df_psy$folded_mu_adj)

```

# Test of empirical cumulative distribution functions


the KS test finds the maximum distance between the ECDFs

a non-parametric test, the KS test can be applied to compare any two distributions regardless of whether you assume normal or uniform. In practice, the KS test is extremely useful because it is efficient and effective at distinguishing a sample from another sample

if two samples belong to each other, their empirical cumulative distribution functions (ECDFs) must be quite similar



https://stats.stackexchange.com/questions/52305/comparison-of-2-distributions/52329#52329

implementation:
https://stat.ethz.ch/R-manual/R-patched/library/stats/html/ks.test.html

good explanations:
https://towardsdatascience.com/how-to-compare-two-distributions-in-practice-8c676904a285

https://stats.stackexchange.com/questions/4/assessing-the-significance-of-differences-in-distributions

https://stats.stackexchange.com/questions/9311/kullback-leibler-vs-kolmogorov-smirnov-distance

pvalue of the KS test: https://stats.stackexchange.com/questions/149595/ks-test-how-is-the-p-value-calculated


Bootstrapping based on the Kolmogorov-Smirnov test
https://cran.r-project.org/web/packages/kldtools/kldtools.pdf

```{r}
#------------------economics------------------#
ks_eco <- ksboot(dat_eco$mu_obs, df_eco$mu_unadj, nboots=5000)
ks_eco2 <- ksboot(df_eco$mu_unadj, df_eco$mu_adj, nboots=5000)
ks_eco3 <- ksboot(abs(df_eco$mu_adj), df_eco$folded_mu_adj, nboots=5000)

# save to save time
#save(ks_eco, file = here("Dat", "ks_eco.rda"))
#save(ks_eco2, file = here("Dat", "ks_eco2.rda"))
#save(ks_eco3, file = here("Dat", "ks_eco3.rda"))
load(file = here("Dat", "ks_eco.rda"))
load(file = here("Dat", "ks_eco2.rda"))
load(file = here("Dat", "ks_eco3.rda"))
load(file = here("Dat", "ks_eco4.rda"))


#------------------environment------------------#
ks_env <- ksboot(dat_env$z, df_env$mu_unadj, nboots=5000)
ks_env2 <- ksboot(df_env$mu_unadj, df_env$mu_adj, nboots=5000)
ks_env3 <- ksboot(abs(df_env$mu_adj), df_env$folded_mu_adj, nboots=5000)
# save to save time
#save(ks_env, file = here("Dat", "ks_env.rda"))
#save(ks_env2, file = here("Dat", "ks_env2.rda"))
#save(ks_env3, file = here("Dat", "ks_env3.rda"))
load(file = here("Dat", "ks_env.rda"))
load(file = here("Dat", "ks_env2.rda"))
load(file = here("Dat", "ks_env3.rda"))

#------------------psychology------------------#
ks_psy <- ksboot(dat_psy$z, df_psy$mu_unadj, nboots=5000)
ks_psy2 <- ksboot(df_psy$mu_unadj, df_psy$mu_adj, nboots=5000)
ks_psy3 <- ksboot(abs(df_psy$mu_adj), df_psy$folded_mu_adj, nboots=5000)
# save to save time
#save(ks_psy, file = here("Dat", "ks_psy.rda"))
#save(ks_psy2, file = here("Dat", "ks_psy2.rda"))
#save(ks_psy3, file = here("Dat", "ks_psy3.rda"))
load(file = here("Dat", "ks_psy.rda"))
load(file = here("Dat", "ks_psy2.rda"))
load(file = here("Dat", "ks_psy3.rda"))


#------------------medicine------------------#
ks_med <- ksboot(dat_med$z, df_med$mu_unadj, nboots=5000)
ks_med2 <- ksboot(df_med$mu_unadj, df_med$mu_adj, nboots=5000)
ks_med3 <- ksboot(abs(df_med$mu_adj), df_med$folded_mu_adj, nboots=5000)
# save to save time
#save(ks_med, file = here("Dat", "ks_med.rda"))
#save(ks_med2, file = here("Dat", "ks_med2.rda"))
#save(ks_med3, file = here("Dat", "ks_med3.rda"))
load(file = here("Dat", "ks_med.rda"))
load(file = here("Dat", "ks_med2.rda"))
load(file = here("Dat", "ks_med3.rda"))

```

# Distribution properity

We use Laplace approximation method to estimate the mode of effect size distributions and use Hartigans' dip test to assess the unimodality.

## Mode estimation

```{r}
#------------------economics------------------#
## bootstrapping for mode
boot_mode_eco <- boot(df_eco$folded_mu_adj, mode_func, R = 5000)
## confidence intervals for mode
boot_mode_eco_ci <- boot.ci(boot_mode_eco, type = "bca") 
## bootstrapping for skewness
boot_skewness_eco <- boot(df_eco$folded_mu_adj, skewness_func, R = 5000)
## confidence intervals for skewness
boot_skewness_eco_ci <- boot.ci(boot_skewness_eco, type = "bca")
## bootstrapping for kurtosis
boot_kurtosis_eco <- boot(df_eco$folded_mu_adj, kurtosis_func, R = 5000)
## confidence intervals for kurtosis
boot_kurtosis_eco_ci <- boot.ci(boot_kurtosis_eco, type = "bca")

# save
#save(boot_mode_eco, file = here("Dat", "boot_mode_eco.rda"))
#save(boot_mode_eco_ci, file = here("Dat", "boot_mode_eco_ci.rda"))
#save(boot_skewness_eco, file = here("Dat", "boot_skewness_eco.rda"))
#save(boot_skewness_eco_ci, file = here("Dat", "boot_skewness_eco_ci.rda"))
#save(boot_kurtosis_eco, file = here("Dat", "boot_kurtosis_eco.rda"))
#save(boot_kurtosis_eco_ci, file = here("Dat", "boot_kurtosis_eco_ci.rda"))
load(file = here("Dat", "boot_mode_eco.rda"))
load(file = here("Dat", "boot_mode_eco_ci.rda"))
load(file = here("Dat", "boot_skewness_eco.rda"))
load(file = here("Dat", "boot_skewness_eco_ci.rda"))
load(file = here("Dat", "boot_kurtosis_eco.rda"))
load(file = here("Dat", "boot_kurtosis_eco_ci.rda"))



#------------------environment------------------#
## bootstrapping for mode
boot_mode_env <- boot(df_env$folded_mu_adj, mode_func, R = 10000)
## confidence intervals for mode
boot_mode_env_ci <- boot.ci(boot_mode_env, type = "bca") 

## bootstrapping for mode2
boot_mode_env2 <- boot(df_env$folded_mu_adj, mode_func2, R = 10000)
## confidence intervals for mode2
boot_mode_env_ci2 <- boot.ci(boot_mode_env2, type = "bca") 

## bootstrapping for skewness
boot_skewness_env <- boot(df_env$folded_mu_adj, skewness_func, R = 5000)
## confidence intervals for skewness
boot_skewness_env_ci <- boot.ci(boot_skewness_env, type = "bca")
## bootstrapping for kurtosis
boot_kurtosis_env <- boot(df_env$folded_mu_adj, kurtosis_func, R = 5000)
## confidence intervals for kurtosis
boot_kurtosis_env_ci <- boot.ci(boot_kurtosis_env, type = "bca")
# save
#save(boot_mode_env, file = here("Dat", "boot_mode_env.rda"))
#save(boot_mode_env_ci, file = here("Dat", "boot_mode_env_ci.rda"))
#save(boot_mode_env2, file = here("Dat", "boot_mode_env2.rda"))
#save(boot_mode_env_ci2, file = here("Dat", "boot_mode_env_ci2.rda"))
#save(boot_skewness_env, file = here("Dat", "boot_skewness_env.rda"))
#save(boot_skewness_env_ci, file = here("Dat", "boot_skewness_env_ci.rda"))
#save(boot_kurtosis_env, file = here("Dat", "boot_kurtosis_env.rda"))
#save(boot_kurtosis_env_ci, file = here("Dat", "boot_kurtosis_env_ci.rda"))
load(file = here("Dat", "boot_mode_env.rda"))
load(file = here("Dat", "boot_mode_env_ci.rda"))
load(file = here("Dat", "boot_mode_env2.rda"))
load(file = here("Dat", "boot_mode_env_ci2.rda"))
load(file = here("Dat", "boot_skewness_env.rda"))
load(file = here("Dat", "boot_skewness_env_ci.rda"))
load(file = here("Dat", "boot_kurtosis_env.rda"))
load(file = here("Dat", "boot_kurtosis_env_ci.rda"))


#------------------psychology------------------#
## bootstrapping for mode
boot_mode_psy <- boot(df_psy$folded_mu_adj, mode_func, R = 5000)
## confidence intervals for mode
boot_mode_psy_ci <- boot.ci(boot_mode_psy, type = "bca") 
## bootstrapping for skewness
boot_skewness_psy <- boot(df_psy$folded_mu_adj, skewness_func, R = 5000)
## confidence intervals for skewness
boot_skewness_psy_ci <- boot.ci(boot_skewness_psy, type = "bca")
## bootstrapping for kurtosis
boot_kurtosis_psy <- boot(df_psy$folded_mu_adj, kurtosis_func, R = 5000)
## confidence intervals for kurtosis
boot_kurtosis_psy_ci <- boot.ci(boot_kurtosis_psy, type = "bca")

# save
#save(boot_mode_psy, file = here("Dat", "boot_mode_psy.rda"))
#save(boot_mode_psy_ci, file = here("Dat", "boot_mode_psy_ci.rda"))
#save(boot_skewness_psy, file = here("Dat", "boot_skewness_psy.rda"))
#save(boot_skewness_psy_ci, file = here("Dat", "boot_skewness_psy_ci.rda"))
#save(boot_kurtosis_psy, file = here("Dat", "boot_kurtosis_psy.rda"))
#save(boot_kurtosis_psy_ci, file = here("Dat", "boot_kurtosis_psy_ci.rda"))
load(file = here("Dat", "boot_mode_psy.rda"))
load(file = here("Dat", "boot_mode_psy_ci.rda"))
load(file = here("Dat", "boot_skewness_psy.rda"))
load(file = here("Dat", "boot_skewness_psy_ci.rda"))
load(file = here("Dat", "boot_kurtosis_psy.rda"))
load(file = here("Dat", "boot_kurtosis_psy_ci.rda"))


#------------------medicine------------------#
## bootstrapping for mode
boot_mode_med <- boot(df_med$folded_mu_adj, mode_func, R = 5000)
## confidence intervals for mode
boot_mode_med_ci <- boot.ci(boot_mode_med, type = "bca") 
## bootstrapping for skewness
boot_skewness_med <- boot(df_med$folded_mu_adj, skewness_func, R = 5000)
## confidence intervals for skewness
boot_skewness_med_ci <- boot.ci(boot_skewness_med, type = "bca")
## bootstrapping for kurtosis
boot_kurtosis_med <- boot(df_med$folded_mu_adj, kurtosis_func, R = 5000)
## confidence intervals for kurtosis
boot_kurtosis_med_ci <- boot.ci(boot_kurtosis_med, type = "bca")
# save
#save(boot_mode_med, file = here("Dat", "boot_mode_med.rda"))
#save(boot_mode_med_ci, file = here("Dat", "boot_mode_med_ci.rda"))
#save(boot_skewness_med, file = here("Dat", "boot_skewness_med.rda"))
#save(boot_skewness_med_ci, file = here("Dat", "boot_skewness_med_ci.rda"))
#save(boot_kurtosis_med, file = here("Dat", "boot_kurtosis_med.rda"))
#save(boot_kurtosis_med_ci, file = here("Dat", "boot_kurtosis_med_ci.rda"))

load(file = here("Dat", "boot_mode_med.rda"))
load(file = here("Dat", "boot_mode_med_ci.rda"))
load(file = here("Dat", "boot_skewness_med.rda"))
load(file = here("Dat", "boot_skewness_med_ci.rda"))
load(file = here("Dat", "boot_kurtosis_med.rda"))
load(file = here("Dat", "boot_kurtosis_med_ci.rda"))

```


## Test for unimodality

https://search.r-project.org/CRAN/refmans/performance/html/check_multimodal.html

https://universeofdatascience.com/how-to-determine-if-data-are-unimodal-or-multimodal-in-r/

mixture model and likelihood ratio test
https://stats.stackexchange.com/questions/138223/how-to-test-if-my-distribution-is-multimodal
https://stats.stackexchange.com/questions/51062/test-for-bimodal-distribution

```{r}
#------------------economics------------------#
dip.test(df_eco$folded_mu_adj)
#------------------environment------------------#
dip.test(df_env$folded_mu_adj)
#------------------medicine------------------#
dip.test(df_med$folded_mu_adj)
#------------------psychology------------------#
dip.test(df_psy$folded_mu_adj)
```


# Benchmark derivation

We report benchmarks based on three ways:

(1) distribution of adjusted and folded estimates,

(2) distribution of adjusted estimates (for the sake of consistence with the literature),

(3) distribution of empirical Bayes (sensitivity analysis).

## Adjusted and folded distribution

```{r}
# d
df %>%
  group_by(discipline) %>%
  summarize(Q1_fold = quantile(folded_mu_adj, probs = 0.25),
            median_fold = quantile(folded_mu_adj, probs = 0.50),
            Q3_fold = quantile(folded_mu_adj, probs = 0.75)) %>% dfround(3)

# r
df_r <- df %>% mutate(mu_adj_r = d2r(mu_adj), 
                      se_adj_r = se_d2se_r(se_adj, mu_adj)) %>%
  mutate(var_adj_r = se_adj_r^2,
         folded_mu_adj_r = folded_es(mu_adj_r, var_adj_r),
         folded_var_adj_r = folded_var(mu_adj_r, var_adj_r))
df_r %>%
  group_by(discipline) %>%
  summarize(Q1_fold = quantile(folded_mu_adj_r, probs = 0.25),
            median_fold = quantile(folded_mu_adj_r, probs = 0.50),
            Q3_fold = quantile(folded_mu_adj_r, probs = 0.75)) %>% dfround(3)

# z
df_Zr <- df_r %>% mutate(mu_adj_Zr = r2z(mu_adj_r), 
                      se_adj_Zr = se_r2se_z(se_adj_r, mu_adj_r)) %>%
  mutate(var_adj_Zr = se_adj_Zr^2,
         folded_mu_adj_Zr = folded_es(mu_adj_Zr, var_adj_Zr),
         folded_var_adj_Zr = folded_var(mu_adj_Zr, var_adj_Zr))

df_Zr %>%
  group_by(discipline) %>%
  summarize(Q1_fold = quantile(folded_mu_adj_Zr, probs = 0.25, na.rm = T),
            median_fold = quantile(folded_mu_adj_Zr, probs = 0.50,  na.rm = T),
            Q3_fold = quantile(folded_mu_adj_Zr, probs = 0.75,  na.rm = T)) %>% dfround(3)



# OR
df_OR <- df %>% mutate(mu_adj_OR = d2logOR(mu_adj), 
                      se_adj_OR = se_d2se_logOR(se_adj, mu_adj_OR)) %>%
  mutate(var_adj_OR = se_adj_OR^2,
         folded_mu_adj_OR = folded_es(mu_adj_OR, var_adj_OR),
         folded_var_adj_OR = folded_var(mu_adj_OR, var_adj_OR))
df_OR %>%
  group_by(discipline) %>%
  summarize(Q1_fold = quantile(folded_mu_adj_OR, probs = 0.25) %>% exp(),
            median_fold = quantile(folded_mu_adj_OR, probs = 0.50) %>% exp(),
            Q3_fold = quantile(folded_mu_adj_OR, probs = 0.75) %>% exp()) %>% dfround(3)

# percentiles with a high resolution

## d
as.numeric(quantile(abs(filter(df, discipline == "economics")$folded_mu_adj), probs = seq(0.05,1,0.05), na.rm = T)) %>% round(3)

as.numeric(quantile(abs(filter(df, discipline == "environmental")$folded_mu_adj), probs = seq(0.05,1,0.05), na.rm = T)) %>% round(3)

as.numeric(quantile(abs(filter(df, discipline == "medicine")$folded_mu_adj), probs = seq(0.05,1,0.05), na.rm = T)) %>% round(3)

as.numeric(quantile(abs(filter(df_r, discipline == "psychology")$folded_mu_adj), probs = seq(0.05,1,0.05), na.rm = T)) %>% round(3)

## r
as.numeric(quantile(abs(filter(df_r, discipline == "economics")$folded_mu_adj_r), probs = seq(0.05,1,0.05), na.rm = T)) %>% round(3)
as.numeric(quantile(abs(filter(df_r, discipline == "environmental")$folded_mu_adj_r), probs = seq(0.05,1,0.05), na.rm = T)) %>% round(3)
as.numeric(quantile(abs(filter(df_r, discipline == "medicine")$folded_mu_adj_r), probs = seq(0.05,1,0.05), na.rm = T)) %>% round(3)
as.numeric(quantile(abs(filter(df_r, discipline == "psychology")$folded_mu_adj_r), probs = seq(0.05,1,0.05), na.rm = T)) %>% round(3)

## Zr
as.numeric(quantile(abs(filter(df_Zr, discipline == "economics")$folded_mu_adj_Zr), probs = seq(0.05,1,0.05), na.rm = T)) %>% round(3)
as.numeric(quantile(abs(filter(df_Zr, discipline == "environmental")$folded_mu_adj_Zr), probs = seq(0.05,1,0.05), na.rm = T)) %>% round(3)
as.numeric(quantile(abs(filter(df_Zr, discipline == "medicine")$folded_mu_adj_Zr), probs = seq(0.05,1,0.05), na.rm = T)) %>% round(3)
as.numeric(quantile(abs(filter(df_Zr, discipline == "psychology")$folded_mu_adj_Zr), probs = seq(0.05,1,0.05), na.rm = T)) %>% round(3)

## OR
as.numeric(quantile(abs(filter(df_OR, discipline == "economics")$folded_mu_adj_OR), probs = seq(0.05,1,0.05), na.rm = T)) %>% round(3)
as.numeric(quantile(abs(filter(df_OR, discipline == "environmental")$folded_mu_adj_OR), probs = seq(0.05,1,0.05), na.rm = T)) %>% round(3)
as.numeric(quantile(abs(filter(df_OR, discipline == "medicine")$folded_mu_adj_OR), probs = seq(0.05,1,0.05), na.rm = T)) %>% round(3)
as.numeric(quantile(abs(filter(df_OR, discipline == "psychology")$folded_mu_adj_OR), probs = seq(0.05,1,0.05), na.rm = T)) %>% round(3)

```


## Adjusted distribution

```{r}
# d
df %>%
  group_by(discipline) %>%
  summarize(Q1 = quantile(mu_adj, probs = 0.25),
            median = quantile(mu_adj, probs = 0.50),
            Q3 = quantile(mu_adj, probs = 0.75)) %>% dfround(3)

# r
df_r %>%
  group_by(discipline) %>%
  summarize(Q1 = quantile(abs(mu_adj_r), probs = 0.25),
            median = quantile(abs(mu_adj_r), probs = 0.50),
            Q3 = quantile(abs(mu_adj_r), probs = 0.75)) %>% dfround(3)

# z
df_Zr %>%
  group_by(discipline) %>%
  summarize(Q1 = quantile(abs(mu_adj_Zr), probs = 0.25, na.rm = T),
            median = quantile(abs(mu_adj_Zr), probs = 0.50,  na.rm = T),
            Q3 = quantile(abs(mu_adj_Zr), probs = 0.75,  na.rm = T)) %>% dfround(3)

# OR
df_OR %>%
  group_by(discipline) %>%
  summarize(Q1 = quantile(abs(mu_adj_OR), probs = 0.25) %>% exp(),
            median = quantile(abs(mu_adj_OR), probs = 0.50) %>% exp(),
            Q3 = quantile(abs(mu_adj_OR), probs = 0.75) %>% exp()) %>% dfround(3)

```

## Empirical Bayes

```{r}
# add blups to the data frame
df$blup <- c(df_eco$blup, df_psy$blup, df_med$blup, df_env$blup)

# d
df %>%
  group_by(discipline) %>%
  summarize(Q1_fold = quantile(blup, probs = 0.25),
            median_fold = quantile(blup, probs = 0.50),
            Q3_fold = quantile(blup, probs = 0.75)) %>% dfround(3)

# r
df_r <- df %>% mutate(blup_r = d2r(blup))

df_r %>%
  group_by(discipline) %>%
  summarize(Q1_fold = quantile(blup_r, probs = 0.25),
            median_fold = quantile(blup_r, probs = 0.50),
            Q3_fold = quantile(blup_r, probs = 0.75)) %>% dfround(3)

# z
df_Zr <- df_r %>% mutate(blup_Zr = r2z(blup_r))

df_Zr %>%
  group_by(discipline) %>%
  summarize(Q1_fold = quantile(blup_Zr, probs = 0.25, na.rm = T),
            median_fold = quantile(blup_Zr, probs = 0.50,  na.rm = T),
            Q3_fold = quantile(blup_Zr, probs = 0.75,  na.rm = T)) %>% dfround(3)



# OR
df_OR <- df %>% mutate(blup_OR = d2logOR(blup))
df_OR %>%
  group_by(discipline) %>%
  summarize(Q1_fold = quantile(blup, probs = 0.25) %>% exp(),
            median_fold = quantile(blup, probs = 0.50) %>% exp(),
            Q3_fold = quantile(blup, probs = 0.75) %>% exp()) %>% dfround(3) 

```

